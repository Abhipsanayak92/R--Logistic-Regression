train<-read.csv(file.choose())
View(train)
summary(train)
data<-read.csv(file.choose())
data<-read.csv(file.choose())
table(data$fgood)
names(data)
str(data)
#data conversion as per model requirement
data$cbs1<-as.numeric(data$cbs1)
data$cbinq<-as.numeric(data$cbinq)
data$cbline<-as.numeric(data$cbline)
data$cbterm<- as.numeric(data$cbterm)
data$cblineut<-as.numeric(data$cblineut)
data$cbtob<-as.numeric(data$cbtob)
#categorical variable
data$fgood<-as.factor(data$fgood)
data$pmt<-as.factor(data$pmt)
data$cbdpd<-as.factor(data$cbdpd)
data$home<-as.factor(data$home)
data$online<-as.factor(data$online)
data$cbnew<-as.factor(data$cbnew)
str(data)
#treatment for outlier for cblineut
boxplot(data$cblineut)
summary(data$cblineut)
upper<-54.089+1.5*IQR(data$cblineut);upper
data$cblineut[data$cblineut>upper]<- upper
lower<-37.734-1.5*IQR(data$cblineut); lower
data$cblineut[data$cblineut<lower]<-lower
boxplot(data$cblineut)
summary(data$cblineut)
#checking missing values
sapply(data, function(x) sum(is.na(x))) ### we found that cbs1 column is having 487 missing values
#cibil score not given means the cust is new
data$cbs1[is.na(data$cbs1)]<-1 #replacing missing values with 1 as per CIBIL
sapply(data, function(x) sum(is.na(x)))
#multiple logistic regression
library(caret)
install.packages("ggplot2")
install.packages("lattice")
install.packages("lattice")
#multiple logistic regression
library(caret)
Train<-createDataPartition(data$fgood, p=0.7, list = FALSE)
training<- data[Train,]
testing<-data[-Train,]
#fitting logistic regression to the training set
classifier=step(glm(fgood~. -period, family = 'binomial',
data=training), direction="both")
summary(classifier) ###classifier is the model name
Acc(classifier)
# concordance and discordance
Acc=function(model){
Data = cbind(model$y, model$fitted.values)
ones = Data[Data[,1] == 1,]
zeros = Data[Data[,1] == 0,]
conc=matrix(0, dim(zeros)[1], dim(ones)[1])
disc=matrix(0, dim(zeros)[1], dim(ones)[1])
ties=matrix(0, dim(zeros)[1], dim(ones)[1])
for (j in 1:dim(zeros)[1])
{
for (i in 1:dim(ones)[1])
{
if (ones[i,2]>zeros[j,2])
{conc[j,i]=1}
else if (ones[i,2]<zeros[j,2])
{disc[j,i]=1}
else if (ones[i,2]==zeros[j,2])
{ties[j,i]=1}
}
}
Pairs=dim(zeros)[1]*dim(ones)[1]
PercentConcordance=(sum(conc)/Pairs)*100
PercentDiscordance=(sum(disc)/Pairs)*100
PercentTied=(sum(ties)/Pairs)*100
return(list("Percent Concordance"=PercentConcordance,"Percent Discordance"=PercentDiscordance,"Percent Tied"=PercentTied,"Pairs"=Pairs))
}
Acc(classifier)
##prediction
testing$probs<-predict(classifier, testing, type='response')
testing$Predict<-as.factor(ifelse(testing$probs>0.70,'1','0'))
View(testing)
View(testing)
table(testing$Predict, testing$fgood)
library(caret)
library(e1071)
confusionMatrix(testing$Predict, testing$fgood)
library(e1071)
table(data$fgood)
#we are doing undersampling here to tackle biasness of data
data2<-subset(data, fgood==1) #we are taking subset where there  are good cust(means fgood ==1)
data3<-subset(data,fgood==0) #we are taking subset where there are bad cust (means fgood==0)
data3<- data3[1:500,]# randomly we can take any numbers
data4<- rbind(data2, data3)
###multiple logistic regression
library(caret)
Train<-createDataPartition(data4$fgood, p= 0.7, list=FALSE)
training<- data4[Train,]
testing<- data4[-Train,]
#fitting logistic regression to the training set
classifier= glm(fgood~.-period, family='binomial', data=training)
summary(classifier)
Acc(classifier)
##prediction
testing$probs<- predict(classifier, testing, type="response")
testing$Predict<-as.factor(ifelse(testing$probs>0.70, '1', '0'))
table(testing$Predict, testing$fgood)
library(caret)
library(e1071)
confusionMatrix(testing$Predict, testing$fgood)
library(ROCR)
#make predictions on test set
predictTrain= predict(classifier,testing, type ="response")
#Prediction function
ROCRpred = prediction(predictTrain, testing$fgood)
#performance function
ROCRperf= performance(ROCRpred, "tpr", "fpr")
##plotting ROC curve
plot(ROCRperf)
#add colors
plot(ROCRperf, colorize=TRUE)
